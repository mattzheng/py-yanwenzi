

from tqdm import tqdm
import jieba_fast as jieba
from flashtext import KeywordProcessor
from rouge import Rouge
from collections import Counter
import re
import numpy as np

class yanwenzi():
    '''
    flashtextæ¯”  å¸¸è§„çš„ç”¨[for]çš„æ–¹å¼è¦å¿«ï¼š6-7å€
    
    yanwenzi_dict,é¢œæ–‡å­—å­—å…¸,{'w(ï¾ŸĞ”ï¾Ÿ)w': 'å•Šå•Š', '(ãƒã¸ï¿£ã€)': 'æŠ½æ³£', '(ï¿£_,ï¿£ )': 'è”‘è§†'}
    
    '''
    def __init__(self,yanwenzi_dict):
        self.yanwenzi_dict = yanwenzi_dict
        self.actree = self.init_processor(yanwenzi_dict)
        self.add_words(yanwenzi_dict,freq = 100,tag = 'ywz')
        
        
    def init_processor(self,yanwenzi_dict):
        actree = KeywordProcessor()
        for word,r_word in yanwenzi_dict.items():
            actree.add_keyword(word,'_{}_'.format(r_word))     # å‘trieæ ‘ä¸­æ·»åŠ å•è¯
        print('success loaded. keyword num : ',len(actree))
        return actree
    
    def actree_add_word(self,yanwenzi_dict_list,tag = 'é¢œæ–‡å­—'):
        '''
        actreeè¯å…¸ä¸­æ–°å¢è¯
        
        æ–°å¢è¯åˆ°æ£€ç´¢çš„è¯å…¸ä¹‹ä¸­æ–¹ä¾¿æ£€ç´¢ä½¿ç”¨
        yanwenzi_dict_list,dict/list,åŒæ—¶ä¸€å¼€å§‹æ²¡æœ‰å®šä¹‰é¢œæ–‡å­—çš„å±æ€§,é‚£ä¹ˆå±æ€§ç»Ÿä¸€å®šä¹‰ä¸º"_é¢œæ–‡å­—_"
        
        '''
        if isinstance(yanwenzi_dict_list,dict):
            for word,r_word in yanwenzi_dict_list.items():
                self.actree.add_keyword(word,'_{}_'.format(r_word))     # å‘trieæ ‘ä¸­æ·»åŠ å•è¯
        elif isinstance(yanwenzi_dict_list,list):
            for word in yanwenzi_dict_list:
                self.actree.add_keyword(word,'_{}_'.format(tag))     # å‘trieæ ‘ä¸­æ·»åŠ å•è¯
        else:
            raise Exception('yanwenzi_dict_list format must be dict or list.')
        print('success loaded. keyword num : ',len(yanwenzi_dict_list))
    
    def add_words(self,yanwenzi_dict_list,freq = 100,tag = 'ywz'):
        '''
        åˆ†è¯è¯å…¸ä¸­åŠ å…¥æ–°å¢çš„è¯
        yanwenzi_dict_list,dict/listéƒ½å¯ä»¥,æ–°å¢åˆ°åˆ†è¯çš„è¯å…¸ä¹‹ä¸­
        '''
        if isinstance(yanwenzi_dict_list,dict):
            for k,v in yanwenzi_dict_list.items():
                jieba.add_word('_{}_'.format(v),freq = freq,tag = tag)
        elif isinstance(yanwenzi_dict_list,list):
            for word in yanwenzi_dict_list:
                jieba.add_word('_{}_'.format(word),freq = freq,tag = tag)
        else:
            raise Exception('yanwenzi_dict_list format must be dict or list.')
        print('jieba add words. length :',len(yanwenzi_dict_list))

    def detect(self,text,span_info=True):
        '''
        span_info:æ˜¯å¦æ ‡è®°ä½ç½®
        '''
        out = self.actree.extract_keywords(text,span_info=span_info)
        return out

    def ywz_replace(self,text):
        return self.actree.replace_keywords(text)

    def jieba_cut(self,text):
        '''
        2020-6-3 å‘ç°'Ä°rem è‰¾ä¸½' - ywz_replace æŠ¥é”™ï¼šIndexError: string index out of range
        '''
        try:
            text = self.ywz_replace(text)
        except:
            pass
        return list(jieba.cut(text))

    '''  æ–°é¢œæ–‡å‘ç°  '''
    @staticmethod
    def is_special_char(text):
        '''
        ç‰¹æ®Šç¬¦å·æ£€æµ‹
        text = 'å°çŒªå“¥ğŸ¹'
        is_special_char(text)
        >>> ['ğŸ¹']

        text = text = 'â™ª Ù©(ï½¡â€¢Ë‡â€¸Ë‡â€¢ï½¡)Û¶'
        [['â™ª', 0],
         ['Ù©', 2],
         ['(', 3]...]

        å…¶ä¸­:
        list(re.finditer(u"([^\u4e00-\u9fa5\u0030-\u0039\u0041-\u005a\u0061-\u007a])",text))
        [<_sre.SRE_Match object; span=(2, 3), match='â•­'>,
         <_sre.SRE_Match object; span=(3, 4), match='('>,]
        '''
        m_text = list(re.finditer(u"([^\u4e00-\u9fa5\u0030-\u0039\u0041-\u005a\u0061-\u007a])",text))
        if len(m_text) > 0:
            return [[mt.group(),mt.span()[1]] for mt in m_text]
        else:
            return []
    
    @staticmethod
    def group_consecutive(a):
        '''
        åˆ†ç¦»æ•°åˆ—ä¸­è¿ç»­çš„æ•´æ•°
        fyi:https://zhuanlan.zhihu.com/p/29558169

        group_consecutive([1,2,3,5,6,7,9,54,215,872,246])
        [array([1, 2, 3]),
         array([5, 6, 7]),
         array([9]),
         array([54]),
         array([215]),
         array([872]),
         array([246])]
        '''
        return np.split(a, np.where(np.diff(a) != 1)[0] + 1)

    def yanwenzi_find(self,text,min_n = 2,remove_spacing = True):
        '''
        é¢œæ–‡å­—å‘ç°å‡½æ•°
            - min_n,ç‰¹æ®Šå­—ç¬¦æ•°é‡å¤§äº2
            - remove_spacing,é¢œæ–‡å­—ä¸­é—´æ˜¯å¦å»æ‰ç©ºæ ¼
        '''
        # è¯†åˆ« + åºåˆ—
        spe_out = self.is_special_char(text)
        split_group = self.group_consecutive([s[1] for s in spe_out])
        ywz_out = []
        for sp in split_group:
            if remove_spacing:
                ywz_t = text[sp[0]-1:sp[-1]].replace(' ','')
            else:
                ywz_t = text[sp[0]-1:sp[-1]]

            if len(ywz_t)> min_n:
                ywz_out.append(ywz_t)
        return ywz_out

    def yanwenzi_new_discovery(self,corpus,min_n = 2,remove_spacing = True,topn = 200):
        '''
        é¢œæ–‡å­—å‘ç°å‡½æ•°
            - min_n,ç‰¹æ®Šå­—ç¬¦æ•°é‡å¤§äº2
            - remove_spacing,é¢œæ–‡å­—ä¸­é—´æ˜¯å¦å»æ‰ç©ºæ ¼
            - topn = 200,è¿”å›æ’åtopnçš„é¢œæ–‡å­—è¡¨æƒ…
            
        è¿”å›:
            [('(^_^)', 1837),
             ('(âˆ©_âˆ©)', 617),
             ('(à¹‘â€¢.â€¢à¹‘)', 314),
             ('(â˜†_â˜†)', 291),
             ('(*^Ï‰^*)', 282),
        '''
        ywz_discovery = []
        for text in tqdm(corpus):
            ywz_discovery.extend(self.yanwenzi_find(text,min_n = min_n,remove_spacing = remove_spacing))
            #print(text,'result ==> ',yanwenzi_find(text,min_n = 2))
        return Counter(ywz_discovery).most_common(topn)
    
    '''é¢œæ–‡å­—å±æ€§è¯†åˆ«:æ–°é¢œæ–‡å­—è¯†åˆ«'''

    @staticmethod
    def rouge_score(text_a,text_b):
        rouge = Rouge()
        rouge_score = rouge.get_scores(' '.join([t for t in text_a]), ' '.join([t for t in text_b]))
        rouge_1 = rouge_score[0]["rouge-1"]
        rouge_2 = rouge_score[0]["rouge-2"]
        return {'rouge-1':rouge_1,'rouge-2':rouge_2}

    def new_yanwenzi_find(self,text_a,min_s = 0.35,\
                          score_type = 'rouge-2',stat = 'f'):
        '''
        é€šè¿‡ç›¸ä¼¼æ‰¾åˆ°æœ€ç›¸ä¼¼è¡¨æƒ…

        ä»rougeçš„è¯„åˆ†æ¥çœ‹ï¼Œrouge-1å¤ªç²—ç³™ï¼›rouge-2æ¯”è¾ƒåˆé€‚ï¼Œ
        ä¸”å‡ ä¸ªç»Ÿè®¡é‡ä¸­ï¼Œf/p/r,fæ•ˆæœæ¯”è¾ƒå¥½ï¼Œp/rå¯èƒ½ä¼šæœ‰æ¯”è¾ƒå¤šçš„é€‰é¡¹ï¼Œä¹Ÿå°±æ˜¯å·®å¼‚æ€§ä¸æ˜æ˜¾

        å‚æ•°:
            - min_s = 0.35,é˜ˆå€¼ï¼Œä¸€å®šè¦ç›¸ä¼¼æ€§å¤§äºæ‰ä¼šç»™å‡ºï¼›å¦‚æœæ˜¯'rouge-1'æ¯”è¾ƒåˆé€‚çš„é˜ˆå€¼åœ¨0.75
            - score_type = 'rouge-2',rougeçš„å¾—åˆ†ç±»å‹,n-grams
            - stat = 'f',é‡‡ç”¨çš„ç»Ÿè®¡é‡

        ç»Ÿè®¡é‡:
            text_a = '(^_^)'
            new_yanwenzi_find(text_a,min_s = 0.35)
            >>> [['(^&^)/', 'å™¢è€¶',0.75]]
        '''
        # æ ¹æ®å·²çŸ¥çš„è¡¨æƒ…åŒ…å±æ€§æ±‚rougeå¾—åˆ†
        scores = []
        for k,v in self.yanwenzi_dict.items():
            score = self.rouge_score(text_a,k)
            scores.append(score[score_type][stat])

        # æ‰¾åˆ°æœ€å¤§å€¼æ—ç¾¤
        max_n = [n for n,s in enumerate(scores) if s == max(scores) and max(scores) > min_s]
        # å®šä½åˆ°è¡¨æƒ…
        detect = [[[k,v,max(scores)] for k,v in  self.yanwenzi_dict.items()][mn]  for mn in max_n]
        #print(text_a,'==>',detect,max_n)
        return detect

    
if __name__ == '__main__':
    '''é¢œæ–‡è¯†åˆ«'''
    # åˆå§‹åŒ–
    json_data = {'w(ï¾ŸĞ”ï¾Ÿ)w': 'å•Šå•Š', '(ãƒã¸ï¿£ã€)': 'æŠ½æ³£', '(ï¿£_,ï¿£ )': 'è”‘è§†'}
    import json
    json_data = open("data/yanwenzi_2.json", "r", encoding="utf-8").read()
    json_data = eval(json_data)
    ywz = yanwenzi(json_data)
    
    # æ£€æµ‹ä½ç½®
    text = '^O^ä½³^O^'
    text = '^O^ä½³^O^w(ï¾ŸĞ”ï¾Ÿ)w'
    ywz.detect(text,span_info=True)
    # [('_å¼å¼_', 0, 3), ('_å¼å¼_', 4, 7)]
    
    # ç‰¹æ®Šä½ç½®è¿›è¡Œæ›¿æ¢
    ywz.ywz_replace(text)
    
    # ç‰¹æ®Šç¬¦å·æ›¿æ¢ + åˆ†è¯
    ywz.jieba_cut(text)
    
    '''æ–°é¢œæ–‡å‘ç°'''
    # å•æ–‡æœ¬ é¢œæ–‡å­—å‘ç°
    text = 'ç’‡å“¥ï¼åŠ æ²¹â†–(^Ï‰^)â†—'
    ywz.yanwenzi_find(text,min_n = 2,remove_spacing = True)
    
    # æ‰¹é‡æ–‡æœ¬ é¢œæ–‡å­—å‘ç°
    corpus = ['d(ÅĞ´Åà¹‘)crush', 'â™ª Ù©(ï½¡â€¢Ë‡â€¸Ë‡â€¢ï½¡)Û¶', 'ã€œ(ï¿£â–½ï¿£ã€œ)', 'æœ¨æœ¨â•­(â•¯Îµâ•°)â•®', 'ToT(^(ã‚¨)^)', 'HLYS(ãƒ¼`Â´ãƒ¼)',
     'O(âˆ©_âˆ©)O', '(^^)ç¬”å°–', 'ç’‡å“¥ï¼åŠ æ²¹â†–(^Ï‰^)â†—', 'èœ•å˜(^_^) \ufeff']
    ywz_new_list = ywz.yanwenzi_new_discovery(corpus,min_n = 2,remove_spacing = True,topn = 200)
    
    # æ–°é¢œæ–‡æ·»åŠ åˆ°åˆ†è¯è¯å…¸
    yanwenzi_dict_list = [ynl[0] for ynl in ywz_new_list]
    ywz.add_words(yanwenzi_dict_list,freq = 100,tag = 'ywz')

    # æ–°é¢œæ–‡æ·»åŠ åˆ°æ£€æµ‹è¯å…¸
    ywz.actree_add_word(yanwenzi_dict_list,tag = 'é¢œæ–‡å­—')

    # æ–°é¢œæ–‡å­—å±æ€§è¯†åˆ«
    text_a = '(^_^)'
    ywz.new_yanwenzi_find(text_a,min_s = 0.35)

